<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="UTF-8">
    <link href="https://fonts.googleapis.com/css2?family=Space+Mono:ital,wght@0,400;0,700;1,400;1,700&display=swap" rel="stylesheet">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="styles.css">
	<title>Dataset</title>
</head>
<body>
       <header>
            <nav>
                <ul>
                    <li><a href="index.html">Home</a></li>
                    <li><a href="dataset.html">Dataset</a></li>
                    <li><a href="algorithm.html">Algorithm</a></li>
                    <li><a href="people.html">People</a></li>
                </ul>
            </nav>
        </header>
        <main>
        <div class ="box1">
            <h1> Dataset</h1>
            <p> The Dataset consists of the top 1000 movies on IMDB in 2020. 
                The original dataset can be found on <a href="https://www.kaggle.com/datasets/harshitshankhdhar/imdb-dataset-of-top-1000-movies-and-tv-shows">Kaggle</a> and consists of 1000 rows and 16 columns. 
            </p>
            <h2>Choosing a dataset</h2>
            <p>
                During the process of deciding which dataset to use for the project, we first considered one dataset related to <a href="https://www.kaggle.com/datasets/datamunge/sign-language-mnist">sign language</a>. 
                Unfortunately the dataset did not contain enough items and we were considering whether we could develop it further to align with the 50 items, 
                which was stated to be the minimum requirement for this project. We quickly set the dataset aside because we realised that it would be too difficult to design a meaningful 
                algorithm based on the specific subject as well as the datatypes it contained. We therefore changed direction and decided to look for a dataset related to movies that could 
                support the function of a movie recommender algorithm. The first movie related dataset contained around 10 000 movies and can be found here:<a href="https://www.kaggle.com/datasets/utkarshvishwakarmaco/tmdb-10000-movies-dataset">TMDB 10000 Movies Dataset</a>. 
                We refined our search further and came across a dataset featuring the top 1000 ranked movies on IMDB. We considered this dataset to better suit the development of the algorithm 
                because the data was already ordered and structured in an intuitive way. We also chose this movie dataset instead of the other since we deemed 10 000 entries to be a bit excessive 
                for the purposes of the algorithm. 
            </p>
                <h2>Data curation</h2> 
<p>The dataset was originally retrieved as a CSV file with all values as strings. The original columns of the dataset was as following: </p>
    <h3>Original CSV Data</h3>
<div class="table-container">
  <table>
    <tr>
      <th scope="col">Poster_Link</th>
      <th scope="col">Series_Title</th>
      <th scope="col">Released_Year</th>
      <th scope="col">Certificate</th>
      <th scope="col">Runtime</th>
      <th scope="col">Genre</th>
      <th scope="col">IMDB_Rating</th>
      <th scope="col">Overview</th>
      <th scope="col">Meta_score</th>
      <th scope="col">Director</th>
      <th scope="col">Star1</th>
      <th scope="col">Star2</th>
      <th scope="col">Star3</th>
      <th scope="col">Star4</th>
      <th scope="col">No_of_Votes</th>
      <th scope="col">Gross</th>
    </tr>
    <tr>
      <td>https://m.media-amazon.com/images/M/MV5BZjc4NDZhZWMtNGEzYS00ZWU2LThlM2ItNTA0YzQ0OTExMTE2XkEyXkFqcGdeQXVyNjUwMzI2NzU@._V1_UY98_CR0,0,67,98_AL_.jpg</td>
      <td>It's a Wonderful Life</td>
      <td>1946</td>
      <td>PG</td>
      <td>130 min</td>
      <td>Drama, Family, Fantasy</td>
      <td>8.6</td>
      <td>An angel is sent from Heaven to help a desperately frustrated businessman by showing him what life would have been like if he had never existed.</td>
      <td>89</td>
      <td>Frank Capra</td>
      <td>James Stewart</td>
      <td>Donna Reed</td>
      <td>Lionel Barrymore</td>
      <td>Thomas Mitchell</td>
      <td>405801</td>
      <td></td>
    </tr>
  </table>
</div>


<p>
In the output above, we can see that there were several mismatched datatypes in the original CSV. For example, “Runtime_Minutes” being a string instead of an int. 
Furthermore, the property “Genre” contained several values within its column and “Stars” were stored in numerous columns. Several keys were considered irrelevant for the 
algorithm, including; “certificate”, “meta-score”, “number of votes”, and “gross”. The keys also did not have a purpose to fulfill for our algorithm and were deleted to not 
store unused values and use unnecessary storage
</p>
<h3>Data serialization</h3>
<p>
To get the algorithm to access the data that it needed, we iterated the dataset and redid the data structure in tabular-format (Excel). 
Doing this also made us find an error in the dataset, which was that one movie was missing several values, so we manually added the values from IMDBs website. 
We also removed the word “min” in “runtime” to make it easier to parse this string to an int. Since CSV doesn't support nested data, we decided to do a data serialization 
and translate the dataset to JSON by implementing functions in python. We converted the four “star columns” into one column called “stars” (same structure as the “Genre column”). we use:
 <pre><code class="python">
r row in read:
genres = [g.strip() for g in row[3].split(",")]
stars = [g.strip() for g in row[7].split(",")]
to get the properties to be outputted in json as an array.
We also used:
 data.append ( { "Released_Year": int(row[1]),
                     "Runtime": int(row[2]),
                     "IMDB_Rating": float(row[4]) 
</code></pre>
to translate the properties that needed to be floats and ints. Another benefit of translating to JSON is the potential to connect the algorithm with an API that returns 
JSON files which would make it easier to get real-time updated movie recommendations. After the data serialization the remaining result was a JSON file still containing the 
1000 movie objects and every object contained 8 keys, consisting of datatypes: int, str, floats and arrays.
</p>
<h3>This is the JSON structure that we settled on:</h3>
<div class="cblock">
        <ol>
            <li>JSON Structure Overview:
                <ul>
                    <li>The root object contains a single key: "moviedb".</li>
                    <li>"moviedb" contains one key: "movies".</li>
                    <li>"movies" is an array (list) of movie objects.</li>
                </ul>
            </li>
            <li>Each movie object contains the following keys:
                <ul>
                    <li>"Series_Title" - the title of the movie (string).</li>
                    <li>"Released_Year" - the year the movie was released (integer).</li>
                    <li>"Runtime"- the movie duration in minutes (integer).</li>
                    <li>"Genre" - an array of genres the movie belongs to (e.g. ["Drama", "Action"]).</li>
                    <li>"IMDB_Rating" - the IMDb rating of the movie (float).</li>
                    <li>"Overview" - a short description of the movie (string).</li>
                    <li>"Director" - the director of the movie (string).</li>
                    <li>"Stars" - an array of main actors (e.g. ["Actor 1", "Actor 2", "Actor 3"]).</li>
                </ul>
            </li>
            <li>Example of a single movie object:
                <ul>
                    <li>
                        <pre>
{
  "Series_Title": "The Shawshank Redemption",
  "Released_Year": 1994,
  "Runtime": 142,
  "Genre": ["Drama"],
  "IMDB_Rating": 9.3,
  "Overview": "Two imprisoned men bond over a number of years, finding solace and eventual redemption through acts of common decency.",
  "Director": "Frank Darabont",
  "Stars": ["Tim Robbins", "Morgan Freeman", "Bob Gunton", "William Sadler"]
}
                        </pre>
                    </li>
                </ul>
            </li>
            <li>The "movies" array contains 1000 objects representing individual movies.</li>
            <li>This structure allows nested data (like Genre and Stars lists) to be easily accessed by the algorithm for filtering and recommendations.</li>
        </ol>
</div>
<h2>Limitations</h2>
<p>
    Some limitations to the dataset include reliability regarding updates and potential bias within the data. Since we have chosen a static dataset and not connected our data to a webcrawler 
    (to scrape IMDB), our data will not be updated when IMDBs data is. If a movie has dropped out of the top 1000 or a new movie has been added, it would not show in our dataset, which means 
    that our dataset will become inaccurate/outdated. The main purpose of our algorithm is to recommend examples of movies to watch. Having a dataset of 1000 movies that had 
    (at some point in time) a high rating on IMDB fulfills that purpose and does not necessarily need to be updated for it to gain value to the user.
</p>
<p>
    According to IMDBs help page (2025), their rating system is applied across their database and includes a complex “voter weighting system” to make sure that the final rating is 
    representative of the general voting population. Since the actual algorithm of the “voter weighting system” is not public, we can not get access to it and fully understand what it 
    entails. For transparency to the user, it could be beneficial to be aware that this does not necessarily mean that the data is actually unbiased. Lauzen (2022) argues that male 
    reviewers in general write more movie reviews than women, in addition she mentions that men are more likely to review movies by male directors which in turn can increase the visibility 
    of such movies in an unfair way. As an example from our dataset we can see from the <a href="https://www.kaggle.com/code/harshitshankhdhar/eda-on-imdb-movies-dataset">EDA</a> on Kaggle that all of the top 10 most occurring directors are male. 
</p>
        </div>
        </main>
    <footer></footer>
</body>
</html>